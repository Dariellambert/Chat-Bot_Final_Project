{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87f812d9-b1ce-4fd5-941d-aaac8f136d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot response: Who is Donald Trump?\n",
      "\n",
      "Donald Trump is a man who has been a Republican for decades. He is the most popular Republican presidential candidate in the history of the United States.\n",
      ". . .\n",
      " (1) The Republican Party has a long history in which it has supported the Republican party. The party has always supported a candidate who is not a Democrat. In fact, the party's primary and general election candidates have been Democrats for many years. (2) In the past, Republicans have supported candidates who were not Democrats. This is because the Democratic Party was founded by the Democrats and the Republicans were founded on the principles of free enterprise and individual liberty. It is also because of this that the GOP has never supported any candidate that is neither\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load the pre-trained GPT-2 model\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Function to handle QA queries\n",
    "def handle_qa_query(question):\n",
    "    inputs = tokenizer.encode(question, return_tensors='pt')\n",
    "    outputs = model.generate(inputs, max_length=150, num_return_sequences=1, no_repeat_ngram_size=2)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# Example interaction with QA chatbot\n",
    "question = \"Who is Donald Trump?\"\n",
    "response = handle_qa_query(question)\n",
    "print(\"Chatbot response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2280ed-0136-466f-94b0-78ef90b51afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "\n",
    "st.title(\"Trivia Answer\")\n",
    "\n",
    "# Input form for feature description\n",
    "feature_description = st.text_area(\"Enter feature description\", \n",
    "                                   placeholder=\"Describe the feature you'd like test cases for...\")\n",
    "\n",
    "# Button to generate test cases\n",
    "if st.button(\"Generate Test Cases\"):\n",
    "    if feature_description.strip():\n",
    "        # Generate test cases using GPT-2\n",
    "        with st.spinner(\"Generating test cases...\"):\n",
    "            trivia_answer = generate_trivia_answer(feature_description)\n",
    "        # Display the generated test cases\n",
    "        st.subheader(\"Generated Test Cases:\")\n",
    "        st.write(trivia_answer)\n",
    "    else:\n",
    "        st.warning(\"Please enter a feature description to generate test cases.\")\n",
    "\n",
    "# Footer information or additional UI elements\n",
    "st.sidebar.title(\"About\")\n",
    "st.sidebar.info(\"\"\"\n",
    "This application generates test cases based on a feature description using GPT-2.\n",
    "GPT-2 is a pre-trained language model that can generate natural language text.\n",
    "You can describe any feature, and it will output test case scenarios, steps, and expected results.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56472436-0dfe-4ebf-a3ed-16ecc752e676",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run app.py & npx localtunnel --port 8501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e948cd89-808d-4104-990b-ee1a7c89cf6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
